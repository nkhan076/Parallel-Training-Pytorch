arguments: Namespace(batch_size=50, epochs=100, gpus=3, nodes=1, nr=0, world_size=3)
start time: 2022-08-31 21:06:11.131174
Epoch [1/100], Step [100/200], Loss: 2.2027
Epoch [1/100], Step [200/200], Loss: 2.0474
Epoch [2/100], Step [100/200], Loss: 1.9298
Epoch [2/100], Step [200/200], Loss: 1.8203
Epoch [3/100], Step [100/200], Loss: 1.7076
Epoch [3/100], Step [200/200], Loss: 1.6320
Epoch [4/100], Step [100/200], Loss: 1.5221
Epoch [4/100], Step [200/200], Loss: 1.4772
Epoch [5/100], Step [100/200], Loss: 1.3691
Epoch [5/100], Step [200/200], Loss: 1.3489
Epoch [6/100], Step [100/200], Loss: 1.2432
Epoch [6/100], Step [200/200], Loss: 1.2424
Epoch [7/100], Step [100/200], Loss: 1.1395
Epoch [7/100], Step [200/200], Loss: 1.1523
Epoch [8/100], Step [100/200], Loss: 1.0531
Epoch [8/100], Step [200/200], Loss: 1.0755
Epoch [9/100], Step [100/200], Loss: 0.9803
Epoch [9/100], Step [200/200], Loss: 1.0094
Epoch [10/100], Step [100/200], Loss: 0.9182
Epoch [10/100], Step [200/200], Loss: 0.9520
Epoch [11/100], Step [100/200], Loss: 0.8645
Epoch [11/100], Step [200/200], Loss: 0.9017
Epoch [12/100], Step [100/200], Loss: 0.8178
Epoch [12/100], Step [200/200], Loss: 0.8574
Epoch [13/100], Step [100/200], Loss: 0.7770
Epoch [13/100], Step [200/200], Loss: 0.8180
Epoch [14/100], Step [100/200], Loss: 0.7409
Epoch [14/100], Step [200/200], Loss: 0.7829
Epoch [15/100], Step [100/200], Loss: 0.7087
Epoch [15/100], Step [200/200], Loss: 0.7513
Epoch [16/100], Step [100/200], Loss: 0.6799
Epoch [16/100], Step [200/200], Loss: 0.7227
Epoch [17/100], Step [100/200], Loss: 0.6540
Epoch [17/100], Step [200/200], Loss: 0.6967
Epoch [18/100], Step [100/200], Loss: 0.6305
Epoch [18/100], Step [200/200], Loss: 0.6729
Epoch [19/100], Step [100/200], Loss: 0.6091
Epoch [19/100], Step [200/200], Loss: 0.6510
Epoch [20/100], Step [100/200], Loss: 0.5894
Epoch [20/100], Step [200/200], Loss: 0.6309
Epoch [21/100], Step [100/200], Loss: 0.5712
Epoch [21/100], Step [200/200], Loss: 0.6123
Epoch [22/100], Step [100/200], Loss: 0.5545
Epoch [22/100], Step [200/200], Loss: 0.5950
Epoch [23/100], Step [100/200], Loss: 0.5390
Epoch [23/100], Step [200/200], Loss: 0.5789
Epoch [24/100], Step [100/200], Loss: 0.5246
Epoch [24/100], Step [200/200], Loss: 0.5639
Epoch [25/100], Step [100/200], Loss: 0.5112
Epoch [25/100], Step [200/200], Loss: 0.5499
Epoch [26/100], Step [100/200], Loss: 0.4986
Epoch [26/100], Step [200/200], Loss: 0.5367
Epoch [27/100], Step [100/200], Loss: 0.4869
Epoch [27/100], Step [200/200], Loss: 0.5244
Epoch [28/100], Step [100/200], Loss: 0.4759
Epoch [28/100], Step [200/200], Loss: 0.5128
Epoch [29/100], Step [100/200], Loss: 0.4655
Epoch [29/100], Step [200/200], Loss: 0.5018
Epoch [30/100], Step [100/200], Loss: 0.4557
Epoch [30/100], Step [200/200], Loss: 0.4914
Epoch [31/100], Step [100/200], Loss: 0.4465
Epoch [31/100], Step [200/200], Loss: 0.4815
Epoch [32/100], Step [100/200], Loss: 0.4378
Epoch [32/100], Step [200/200], Loss: 0.4722
Epoch [33/100], Step [100/200], Loss: 0.4295
Epoch [33/100], Step [200/200], Loss: 0.4633
Epoch [34/100], Step [100/200], Loss: 0.4217
Epoch [34/100], Step [200/200], Loss: 0.4549
Epoch [35/100], Step [100/200], Loss: 0.4142
Epoch [35/100], Step [200/200], Loss: 0.4468
Epoch [36/100], Step [100/200], Loss: 0.4071
Epoch [36/100], Step [200/200], Loss: 0.4391
Epoch [37/100], Step [100/200], Loss: 0.4004
Epoch [37/100], Step [200/200], Loss: 0.4318
Epoch [38/100], Step [100/200], Loss: 0.3939
Epoch [38/100], Step [200/200], Loss: 0.4247
Epoch [39/100], Step [100/200], Loss: 0.3878
Epoch [39/100], Step [200/200], Loss: 0.4180
Epoch [40/100], Step [100/200], Loss: 0.3819
Epoch [40/100], Step [200/200], Loss: 0.4116
Epoch [41/100], Step [100/200], Loss: 0.3763
Epoch [41/100], Step [200/200], Loss: 0.4054
Epoch [42/100], Step [100/200], Loss: 0.3709
Epoch [42/100], Step [200/200], Loss: 0.3994
Epoch [43/100], Step [100/200], Loss: 0.3657
Epoch [43/100], Step [200/200], Loss: 0.3937
Epoch [44/100], Step [100/200], Loss: 0.3608
Epoch [44/100], Step [200/200], Loss: 0.3882
Epoch [45/100], Step [100/200], Loss: 0.3560
Epoch [45/100], Step [200/200], Loss: 0.3830
Epoch [46/100], Step [100/200], Loss: 0.3515
Epoch [46/100], Step [200/200], Loss: 0.3779
Epoch [47/100], Step [100/200], Loss: 0.3471
Epoch [47/100], Step [200/200], Loss: 0.3730
Epoch [48/100], Step [100/200], Loss: 0.3429
Epoch [48/100], Step [200/200], Loss: 0.3683
Epoch [49/100], Step [100/200], Loss: 0.3389
Epoch [49/100], Step [200/200], Loss: 0.3637
Epoch [50/100], Step [100/200], Loss: 0.3350
Epoch [50/100], Step [200/200], Loss: 0.3593
Epoch [51/100], Step [100/200], Loss: 0.3312
Epoch [51/100], Step [200/200], Loss: 0.3550
Epoch [52/100], Step [100/200], Loss: 0.3276
Epoch [52/100], Step [200/200], Loss: 0.3509
Epoch [53/100], Step [100/200], Loss: 0.3241
Epoch [53/100], Step [200/200], Loss: 0.3469
Epoch [54/100], Step [100/200], Loss: 0.3207
Epoch [54/100], Step [200/200], Loss: 0.3430
Epoch [55/100], Step [100/200], Loss: 0.3174
Epoch [55/100], Step [200/200], Loss: 0.3393
Epoch [56/100], Step [100/200], Loss: 0.3142
Epoch [56/100], Step [200/200], Loss: 0.3356
Epoch [57/100], Step [100/200], Loss: 0.3112
Epoch [57/100], Step [200/200], Loss: 0.3321
Epoch [58/100], Step [100/200], Loss: 0.3082
Epoch [58/100], Step [200/200], Loss: 0.3286
Epoch [59/100], Step [100/200], Loss: 0.3053
Epoch [59/100], Step [200/200], Loss: 0.3252
Epoch [60/100], Step [100/200], Loss: 0.3025
Epoch [60/100], Step [200/200], Loss: 0.3219
Epoch [61/100], Step [100/200], Loss: 0.2998
Epoch [61/100], Step [200/200], Loss: 0.3188
Epoch [62/100], Step [100/200], Loss: 0.2972
Epoch [62/100], Step [200/200], Loss: 0.3156
Epoch [63/100], Step [100/200], Loss: 0.2947
Epoch [63/100], Step [200/200], Loss: 0.3126
Epoch [64/100], Step [100/200], Loss: 0.2922
Epoch [64/100], Step [200/200], Loss: 0.3097
Epoch [65/100], Step [100/200], Loss: 0.2898
Epoch [65/100], Step [200/200], Loss: 0.3068
Epoch [66/100], Step [100/200], Loss: 0.2875
Epoch [66/100], Step [200/200], Loss: 0.3040
Epoch [67/100], Step [100/200], Loss: 0.2852
Epoch [67/100], Step [200/200], Loss: 0.3012
Epoch [68/100], Step [100/200], Loss: 0.2830
Epoch [68/100], Step [200/200], Loss: 0.2986
Epoch [69/100], Step [100/200], Loss: 0.2808
Epoch [69/100], Step [200/200], Loss: 0.2959
Epoch [70/100], Step [100/200], Loss: 0.2788
Epoch [70/100], Step [200/200], Loss: 0.2934
Epoch [71/100], Step [100/200], Loss: 0.2768
Epoch [71/100], Step [200/200], Loss: 0.2909
Epoch [72/100], Step [100/200], Loss: 0.2748
Epoch [72/100], Step [200/200], Loss: 0.2885
Epoch [73/100], Step [100/200], Loss: 0.2729
Epoch [73/100], Step [200/200], Loss: 0.2861
Epoch [74/100], Step [100/200], Loss: 0.2710
Epoch [74/100], Step [200/200], Loss: 0.2838
Epoch [75/100], Step [100/200], Loss: 0.2692
Epoch [75/100], Step [200/200], Loss: 0.2815
Epoch [76/100], Step [100/200], Loss: 0.2674
Epoch [76/100], Step [200/200], Loss: 0.2793
Epoch [77/100], Step [100/200], Loss: 0.2657
Epoch [77/100], Step [200/200], Loss: 0.2772
Epoch [78/100], Step [100/200], Loss: 0.2640
Epoch [78/100], Step [200/200], Loss: 0.2751
Epoch [79/100], Step [100/200], Loss: 0.2623
Epoch [79/100], Step [200/200], Loss: 0.2730
Epoch [80/100], Step [100/200], Loss: 0.2607
Epoch [80/100], Step [200/200], Loss: 0.2710
Epoch [81/100], Step [100/200], Loss: 0.2591
Epoch [81/100], Step [200/200], Loss: 0.2691
Epoch [82/100], Step [100/200], Loss: 0.2575
Epoch [82/100], Step [200/200], Loss: 0.2671
Epoch [83/100], Step [100/200], Loss: 0.2560
Epoch [83/100], Step [200/200], Loss: 0.2653
Epoch [84/100], Step [100/200], Loss: 0.2545
Epoch [84/100], Step [200/200], Loss: 0.2634
Epoch [85/100], Step [100/200], Loss: 0.2531
Epoch [85/100], Step [200/200], Loss: 0.2616
Epoch [86/100], Step [100/200], Loss: 0.2516
Epoch [86/100], Step [200/200], Loss: 0.2599
Epoch [87/100], Step [100/200], Loss: 0.2502
Epoch [87/100], Step [200/200], Loss: 0.2581
Epoch [88/100], Step [100/200], Loss: 0.2489
Epoch [88/100], Step [200/200], Loss: 0.2564
Epoch [89/100], Step [100/200], Loss: 0.2475
Epoch [89/100], Step [200/200], Loss: 0.2548
Epoch [90/100], Step [100/200], Loss: 0.2462
Epoch [90/100], Step [200/200], Loss: 0.2531
Epoch [91/100], Step [100/200], Loss: 0.2449
Epoch [91/100], Step [200/200], Loss: 0.2515start time: 2022-08-31 21:06:11.139559
end time: 2022-08-31 21:10:19.540860
Training complete in: 0:04:08.401301
start time: 2022-08-31 21:06:11.136766
end time: 2022-08-31 21:10:19.560176
Training complete in: 0:04:08.423410

Epoch [92/100], Step [100/200], Loss: 0.2436
Epoch [92/100], Step [200/200], Loss: 0.2499
Epoch [93/100], Step [100/200], Loss: 0.2424
Epoch [93/100], Step [200/200], Loss: 0.2483
Epoch [94/100], Step [100/200], Loss: 0.2412
Epoch [94/100], Step [200/200], Loss: 0.2468
Epoch [95/100], Step [100/200], Loss: 0.2400
Epoch [95/100], Step [200/200], Loss: 0.2453
Epoch [96/100], Step [100/200], Loss: 0.2388
Epoch [96/100], Step [200/200], Loss: 0.2438
Epoch [97/100], Step [100/200], Loss: 0.2377
Epoch [97/100], Step [200/200], Loss: 0.2424
Epoch [98/100], Step [100/200], Loss: 0.2365
Epoch [98/100], Step [200/200], Loss: 0.2410
Epoch [99/100], Step [100/200], Loss: 0.2354
Epoch [99/100], Step [200/200], Loss: 0.2396
Epoch [100/100], Step [100/200], Loss: 0.2343
Epoch [100/100], Step [200/200], Loss: 0.2382
end time: 2022-08-31 21:10:19.578016
Training complete in: 0:04:08.446842
Training complete in: 0:04:08.446866
